"""
LongMemEval æ•°æ®é›†åŠ è½½æ¨¡å—

åŸºäº mem0 æ¥å£è®¾è®¡çš„æ•°æ®é›†åŠ è½½å‡½æ•°ï¼Œæ”¯æŒå°† LongMemEval æ•°æ®é›†çš„å¯¹è¯å†å²
åŠ è½½åˆ° mem0 è®°å¿†ç³»ç»Ÿä¸­ï¼Œå¹¶è¿›è¡Œé—®ç­”è¯„ä¼°ã€‚
"""

import json
import os
from typing import Dict, List, Any, Optional, Tuple
from pathlib import Path
from mem0 import Memory
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

config = {
    "llm": {
        "provider": "openai",
        "config": {
            "model": "gpt-5-nano", 
            "temperature": 0.1, 
            "api_key": os.getenv("CLOSEAI_API_KEY"),
            "openai_base_url": "https://api.openai-proxy.org/v1",
        },
    },
    # "llm": {
    #     "provider": "deepseek",
    #     "config":{
    #         "model":"deepseek-chat",
    #         "temperature":0.1,
    #         "api_key":os.getenv("DEEPSEEK_API_KEY"),
    #     }
    # },
    "reranker": {
        "provider": "huggingface",
        "config": {
            "model": "BAAI/bge-reranker-base",
            "device": "cuda",
            "batch_size": 32
        }
    },
    "embedder": {
        "provider": "huggingface",
        "config": {
            "model": "all-MiniLM-L6-v2"
        },
    },
    "vector_store": {
        "provider": "qdrant",
        "config": {
            "embedding_model_dims": 384
        }
    }
}


def load_dataset(dataset_path: str, sample_indices: Optional[List[int]] = None) -> List[Dict[str, Any]]:
    """
    åŠ è½½ LongMemEval æ•°æ®é›†æ–‡ä»¶ï¼ˆçº¯æ•°æ®åŠ è½½ï¼Œä¸æ¶‰åŠè®°å¿†ç³»ç»Ÿï¼‰
    
    æ•°æ®é›†ç»“æ„è¯´æ˜ï¼š
    - longmemeval_s_cleaned.json: åŒ…å«500ä¸ªæ ·æœ¬çš„åˆ—è¡¨
    - æ¯ä¸ªæ ·æœ¬åŒ…å«ï¼š
        - question_id: é—®é¢˜å”¯ä¸€æ ‡è¯†
        - question_type: é—®é¢˜ç±»å‹ï¼ˆsingle-session-user, temporal-reasoningç­‰ï¼‰
        - question: é—®é¢˜æ–‡æœ¬
        - answer: æ ‡å‡†ç­”æ¡ˆ
        - haystack_sessions: å¯¹è¯å†å²åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªsessionï¼ˆå¯¹è¯åˆ—è¡¨ï¼‰
        - haystack_session_ids: å¯¹è¯sessionçš„IDåˆ—è¡¨
        - haystack_dates: å¯¹è¯çš„æ—¶é—´æˆ³åˆ—è¡¨
        - answer_session_ids: åŒ…å«ç­”æ¡ˆçš„session IDåˆ—è¡¨
    
    Args:
        dataset_path: æ•°æ®é›† JSON æ–‡ä»¶è·¯å¾„ï¼Œæ”¯æŒä»¥ä¸‹æ ¼å¼ï¼š
            1. longmemeval_s_cleaned.json (ç›´æ¥åŒ…å«æ ·æœ¬åˆ—è¡¨)
            2. extracted_samples_index_X.json (åŒ…å« "samples" å­—æ®µçš„å­—å…¸)
        sample_indices: è¦åŠ è½½çš„æ ·æœ¬ç´¢å¼•åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºåŠ è½½æ‰€æœ‰æ ·æœ¬
            
    Returns:
        æ•°æ®é›†æ ·æœ¬åˆ—è¡¨ï¼Œæ¯ä¸ªæ ·æœ¬æ˜¯ä¸€ä¸ªå­—å…¸
        
    Raises:
        FileNotFoundError: æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨
        ValueError: æ•°æ®æ ¼å¼ä¸æ”¯æŒ
        
    Examples:
        >>> # åŠ è½½å®Œæ•´æ•°æ®é›†
        >>> samples = load_dataset("longmemeval_s_cleaned.json")
        >>> print(f"åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
        
        >>> # åŠ è½½æŒ‡å®šæ ·æœ¬
        >>> samples = load_dataset("longmemeval_s_cleaned.json", sample_indices=[0, 1, 2])
        >>> print(f"åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
    """
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_path):
        raise FileNotFoundError(f"æ•°æ®é›†æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}")
    
    logger.info(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {dataset_path}")
    
    # è¯»å– JSON æ–‡ä»¶
    with open(dataset_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    # å¤„ç†ä¸åŒçš„æ•°æ®æ ¼å¼
    samples = []
    
    if isinstance(data, list):
        # æ ¼å¼1: ç›´æ¥çš„åˆ—è¡¨æ ¼å¼ (longmemeval_s_cleaned.json, longmemeval_m_cleaned.json)
        # [{"question_id": "xxx", "question": "...", ...}, ...]
        samples = data
        logger.info(f"æ£€æµ‹åˆ°ç›´æ¥åˆ—è¡¨æ ¼å¼ï¼ŒåŒ…å« {len(samples)} ä¸ªæ ·æœ¬")
        
    elif isinstance(data, dict):
        if 'samples' in data:
            # æ ¼å¼2: åŒ…å« "samples" å­—æ®µçš„å­—å…¸ (extracted_samples_index_X.json)
            # {"metadata": {...}, "samples": [...]}
            samples = data['samples']
            logger.info(f"æ£€æµ‹åˆ°å¸¦ metadata çš„æ ¼å¼ï¼ŒåŒ…å« {len(samples)} ä¸ªæ ·æœ¬")
            
            # å¯é€‰ï¼šè®°å½• metadata ä¿¡æ¯
            if 'metadata' in data:
                metadata = data['metadata']
                logger.debug(f"æ•°æ®é›† metadata: {metadata}")
        else:
            raise ValueError(
                f"ä¸æ”¯æŒçš„æ•°æ®æ ¼å¼ã€‚æœŸæœ›çš„æ ¼å¼:\n"
                f"1. ç›´æ¥åˆ—è¡¨: [{{'question_id': ..., ...}}, ...]\n"
                f"2. å¸¦ samples å­—æ®µ: {{'samples': [...]}}\n"
                f"å®é™…æ”¶åˆ°çš„é¡¶å±‚å­—æ®µ: {list(data.keys())}"
            )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ•°æ®ç±»å‹: {type(data)}ï¼ŒæœŸæœ› list æˆ– dict")
    
    # éªŒè¯æ ·æœ¬æ ¼å¼
    if len(samples) > 0:
        required_fields = ['question_id', 'question', 'answer', 'haystack_sessions']
        sample_keys = set(samples[0].keys())
        missing_fields = [f for f in required_fields if f not in sample_keys]
        
        if missing_fields:
            logger.warning(f"æ ·æœ¬ç¼ºå°‘ä»¥ä¸‹å­—æ®µ: {missing_fields}")
    
    # å¦‚æœæŒ‡å®šäº†æ ·æœ¬ç´¢å¼•ï¼Œåªè¿”å›æŒ‡å®šçš„æ ·æœ¬
    if sample_indices is not None:
        logger.info(f"ç­›é€‰æ ·æœ¬ç´¢å¼•: {sample_indices}")
        
        # è¿‡æ»¤æœ‰æ•ˆç´¢å¼•
        valid_indices = [i for i in sample_indices if 0 <= i < len(samples)]
        invalid_indices = [i for i in sample_indices if i < 0 or i >= len(samples)]
        
        if invalid_indices:
            logger.warning(f"ä»¥ä¸‹ç´¢å¼•è¶…å‡ºèŒƒå›´ï¼Œå°†è¢«å¿½ç•¥: {invalid_indices} (æ€»æ ·æœ¬æ•°: {len(samples)})")
        
        samples = [samples[i] for i in valid_indices]
        logger.info(f"ç­›é€‰åä¿ç•™ {len(samples)} ä¸ªæ ·æœ¬")
    
    logger.info(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼Œå…± {len(samples)} ä¸ªæ ·æœ¬")
    
    return samples


class LongMemEvalLoader:
    """LongMemEval æ•°æ®é›†åŠ è½½å™¨ï¼ˆåŒ…å«è®°å¿†ç³»ç»Ÿé›†æˆï¼‰"""
    
    def __init__(self, memory: Optional[Memory] = None):
        """
        åˆå§‹åŒ–åŠ è½½å™¨
        
        Args:
            memory: mem0 Memory å®ä¾‹ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤é…ç½®åˆ›å»ºæ–°å®ä¾‹
        """
        self.memory = memory if memory is not None else Memory.from_config(config)
    
    def load_dataset(self, dataset_path: str, sample_indices: Optional[List[int]] = None) -> List[Dict[str, Any]]:
        """
        åŠ è½½ LongMemEval æ•°æ®é›†æ–‡ä»¶ï¼ˆå§”æ‰˜ç»™å…¨å±€ load_dataset å‡½æ•°ï¼‰
        
        Args:
            dataset_path: æ•°æ®é›† JSON æ–‡ä»¶è·¯å¾„
            sample_indices: è¦åŠ è½½çš„æ ·æœ¬ç´¢å¼•åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºåŠ è½½æ‰€æœ‰æ ·æœ¬
            
        Returns:
            æ•°æ®é›†æ ·æœ¬åˆ—è¡¨
        """
        return load_dataset(dataset_path, sample_indices)
    
    def add_conversations_to_memory(
        self, 
        sample: Dict[str, Any],
        sample_idx: int,
        user_id_base: Optional[str] = None,
        infer: bool = True,
        clean_before_add: bool = True
    ) -> Dict[str, Any]:
        """
        å°†æ ·æœ¬çš„å¯¹è¯å†å²æ·»åŠ åˆ° mem0 è®°å¿†ä¸­
        
        ã€æ ¸å¿ƒéš”ç¦»æœºåˆ¶ã€‘å‚è€ƒ Mem0 å¯¹ LOCOMO10 çš„å¤„ç†æ–¹å¼ï¼š
        - ä¸ºæ¯ä¸ªæ ·æœ¬åˆ›å»ºå”¯ä¸€çš„ user_id: f"{user_id_base}_{sample_idx}"
        - ä¾‹å¦‚: sample_0, sample_1, sample_2, ..., sample_499
        - è¿™æ ·ç¡®ä¿500ä¸ªæ ·æœ¬ä¹‹é—´çš„è®°å¿†å®Œå…¨éš”ç¦»ï¼Œäº’ä¸å¹²æ‰°
        
        Args:
            sample: æ•°æ®é›†æ ·æœ¬ï¼ˆå¿…é¡»åŒ…å« haystack_sessions å­—æ®µï¼‰
            sample_idx: æ ·æœ¬ç´¢å¼•ï¼ˆ0-499ï¼‰ï¼Œç”¨äºç”Ÿæˆå”¯ä¸€çš„ user_id
            user_id_base: user_id çš„åŸºç¡€åç§°ï¼Œé»˜è®¤ä½¿ç”¨ "sample"
            infer: æ˜¯å¦å¯ç”¨ mem0 çš„æ¨ç†åŠŸèƒ½ï¼ˆè®°å¿†æå–å’Œæ›´æ–°ï¼‰
            clean_before_add: æ˜¯å¦åœ¨æ·»åŠ å‰æ¸…ç©ºè¯¥ user_id çš„æ‰€æœ‰è®°å¿†ï¼ˆç¡®ä¿å¹²å‡€çŠ¶æ€ï¼‰
            
        Returns:
            åŒ…å«æ·»åŠ ç»“æœçš„å­—å…¸ï¼ŒåŒ…æ‹¬ï¼š
                - question_id: é—®é¢˜ID
                - sample_idx: æ ·æœ¬ç´¢å¼•
                - user_id: å”¯ä¸€çš„ç”¨æˆ·ID
                - total_sessions: æ€»sessionæ•°
                - added_sessions: æˆåŠŸæ·»åŠ çš„sessionæ•°
                - failed_sessions: å¤±è´¥çš„sessionæ•°
                - memory_results: æ¯ä¸ªsessionçš„æ·»åŠ ç»“æœåˆ—è¡¨
        """
        question_id = sample.get('question_id', 'unknown')
        
        # ğŸ”¥ æ ¸å¿ƒï¼šç”Ÿæˆå”¯ä¸€çš„ user_idï¼ˆç±»ä¼¼ Mem0 çš„ f"{speaker_a}_{idx}" æœºåˆ¶ï¼‰
        if user_id_base is None:
            user_id_base = "sample"
        user_id = f"{user_id_base}_{sample_idx}"
        
        # ğŸ”¥ å…ˆæ¸…ç©ºè¯¥æ ·æœ¬çš„æ‰€æœ‰è®°å¿†ï¼ˆç¡®ä¿å¹²å‡€çŠ¶æ€ï¼Œé¿å…è·¨æ ·æœ¬æ±¡æŸ“ï¼‰
        if clean_before_add:
            try:
                self.memory.delete_all(user_id=user_id)
                logger.info(f"[æ ·æœ¬ {sample_idx}] å·²æ¸…ç©º user_id={user_id} çš„æ‰€æœ‰è®°å¿†")
            except Exception as e:
                logger.warning(f"[æ ·æœ¬ {sample_idx}] æ¸…ç©ºè®°å¿†å¤±è´¥: {e}")
        
        # è·å–æ‰€æœ‰å¯¹è¯ sessions
        haystack_sessions = sample.get('haystack_sessions', [])
        
        results = {
            'question_id': question_id,
            'sample_idx': sample_idx,
            'user_id': user_id,
            'total_sessions': len(haystack_sessions),
            'added_sessions': 0,
            'failed_sessions': 0,
            'memory_results': []
        }
        
        # é€ä¸ªæ·»åŠ å¯¹è¯ session
        for session_idx, session in enumerate(haystack_sessions):
            # è·³è¿‡ç©º session
            if not session or not isinstance(session, list):
                logger.debug(f"[æ ·æœ¬ {sample_idx}] è·³è¿‡ç©º session {session_idx}")
                results['failed_sessions'] += 1
                continue
            
            try:
                # å°†å¯¹è¯å†å²æ·»åŠ åˆ° mem0
                # session æ ¼å¼: [{"role": "user", "content": "..."}, {"role": "assistant", "content": "..."}, ...]
                result = self.memory.add(
                    messages=session,
                    user_id=user_id,  # ğŸ”¥ ä½¿ç”¨å”¯ä¸€çš„ user_id
                    infer=infer
                )
                
                results['memory_results'].append({
                    'session_idx': session_idx,
                    'session_length': len(session),
                    'result': result
                })
                results['added_sessions'] += 1
                
                logger.debug(f"[æ ·æœ¬ {sample_idx}] Session {session_idx} æ·»åŠ æˆåŠŸ ({len(session)} æ¡æ¶ˆæ¯)")
                
            except Exception as e:
                logger.error(f"[æ ·æœ¬ {sample_idx}] æ·»åŠ  session {session_idx} å¤±è´¥: {e}")
                results['failed_sessions'] += 1
        
        logger.info(
            f"[æ ·æœ¬ {sample_idx}] user_id={user_id}: "
            f"æˆåŠŸæ·»åŠ  {results['added_sessions']}/{results['total_sessions']} ä¸ªå¯¹è¯"
        )
        
        return results
    
    def query_memory(
        self, 
        question: str,
        sample_idx: int,
        user_id_base: Optional[str] = None,
        top_k: int = 5
    ) -> List[Dict[str, Any]]:
        """
        æ ¹æ®é—®é¢˜æŸ¥è¯¢ç›¸å…³è®°å¿†
        
        Args:
            question: é—®é¢˜æ–‡æœ¬
            sample_idx: æ ·æœ¬ç´¢å¼•ï¼Œç”¨äºç”Ÿæˆå¯¹åº”çš„ user_id
            user_id_base: user_id çš„åŸºç¡€åç§°ï¼Œé»˜è®¤ä½¿ç”¨ "sample"
            top_k: è¿”å›çš„è®°å¿†æ•°é‡
            
        Returns:
            ç›¸å…³è®°å¿†åˆ—è¡¨
        """
        # ç”Ÿæˆä¸ add_conversations_to_memory ç›¸åŒçš„ user_id
        if user_id_base is None:
            user_id_base = "sample"
        user_id = f"{user_id_base}_{sample_idx}"
        
        try:
            memories = self.memory.search(
                query=question,
                user_id=user_id,
                limit=top_k
            )
            logger.info(f"[æ ·æœ¬ {sample_idx}] æŸ¥è¯¢åˆ° {len(memories)} æ¡ç›¸å…³è®°å¿†")
            return memories
            
        except Exception as e:
            logger.error(f"[æ ·æœ¬ {sample_idx}] æŸ¥è¯¢è®°å¿†å¤±è´¥: {e}")
            return []
    
    def process_sample(
        self,
        sample: Dict[str, Any],
        sample_idx: int,
        user_id_base: Optional[str] = None,
        infer: bool = True,
        query_top_k: int = 5,
        clean_before_add: bool = True
    ) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªæ ·æœ¬ï¼šæ¸…ç©ºè®°å¿† -> åŠ è½½å¯¹è¯å†å² -> æŸ¥è¯¢é—®é¢˜ -> è¿”å›ç»“æœ
        
        ã€æ ¸å¿ƒéš”ç¦»æœºåˆ¶ã€‘ï¼š
        - æ¯ä¸ªæ ·æœ¬ä½¿ç”¨å”¯ä¸€çš„ user_id: f"{user_id_base}_{sample_idx}"
        - å¤„ç†å‰å…ˆæ¸…ç©ºè¯¥ user_id çš„æ‰€æœ‰è®°å¿†
        - ç¡®ä¿æ ·æœ¬ä¹‹é—´å®Œå…¨éš”ç¦»ï¼Œäº’ä¸å¹²æ‰°
        
        Args:
            sample: æ•°æ®é›†æ ·æœ¬
            sample_idx: æ ·æœ¬ç´¢å¼•ï¼ˆ0-499ï¼‰
            user_id_base: user_id çš„åŸºç¡€åç§°ï¼Œé»˜è®¤ä½¿ç”¨ "sample"
            infer: æ˜¯å¦å¯ç”¨æ¨ç†
            query_top_k: æŸ¥è¯¢è¿”å›çš„è®°å¿†æ•°é‡
            clean_before_add: æ˜¯å¦åœ¨æ·»åŠ å‰æ¸…ç©ºè®°å¿†
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸ï¼ŒåŒ…æ‹¬ï¼š
                - question_id: é—®é¢˜ID
                - sample_idx: æ ·æœ¬ç´¢å¼•
                - user_id: å”¯ä¸€çš„ç”¨æˆ·ID
                - question: é—®é¢˜æ–‡æœ¬
                - question_type: é—®é¢˜ç±»å‹
                - gold_answer: æ ‡å‡†ç­”æ¡ˆ
                - question_date: é—®é¢˜æ—¥æœŸ
                - add_result: æ·»åŠ å¯¹è¯å†å²çš„ç»“æœ
                - retrieved_memories: æ£€ç´¢åˆ°çš„è®°å¿†åˆ—è¡¨
                - num_memories: æ£€ç´¢åˆ°çš„è®°å¿†æ•°é‡
        """
        question_id = sample.get('question_id', 'unknown')
        
        # ç”Ÿæˆå”¯ä¸€çš„ user_id
        if user_id_base is None:
            user_id_base = "sample"
        user_id = f"{user_id_base}_{sample_idx}"
        
        logger.info(f"[æ ·æœ¬ {sample_idx}] å¼€å§‹å¤„ç† question_id={question_id}, user_id={user_id}")
        
        # 1. æ·»åŠ å¯¹è¯å†å²åˆ°è®°å¿†ï¼ˆå†…éƒ¨ä¼šå…ˆæ¸…ç©ºï¼‰
        add_result = self.add_conversations_to_memory(
            sample=sample,
            sample_idx=sample_idx,
            user_id_base=user_id_base,
            infer=infer,
            clean_before_add=clean_before_add
        )
        
        # 2. æŸ¥è¯¢é—®é¢˜
        question = sample.get('question', '')
        logger.info(f"[æ ·æœ¬ {sample_idx}] æŸ¥è¯¢é—®é¢˜: {question}")
        memories = self.query_memory(
            question=question,
            sample_idx=sample_idx,
            user_id_base=user_id_base,
            top_k=query_top_k
        )
        
        # 3. è¿”å›å®Œæ•´ç»“æœ
        return {
            'question_id': question_id,
            'sample_idx': sample_idx,
            'user_id': user_id,
            'question': question,
            'question_type': sample.get('question_type', 'unknown'),
            'gold_answer': sample.get('answer', ''),
            'question_date': sample.get('question_date', ''),
            'add_result': add_result,
            'retrieved_memories': memories,
            'num_memories': len(memories)
        }
    
    def reset_memory(self, sample_idx: Optional[int] = None, user_id_base: Optional[str] = None):
        """
        æ¸…ç©ºè®°å¿†
        
        Args:
            sample_idx: å¦‚æœæä¾›ï¼Œåªæ¸…ç©ºè¯¥æ ·æœ¬å¯¹åº”çš„è®°å¿†ï¼›å¦åˆ™æ¸…ç©ºæ‰€æœ‰è®°å¿†
            user_id_base: user_id çš„åŸºç¡€åç§°ï¼Œé»˜è®¤ä½¿ç”¨ "sample"
        """
        if sample_idx is not None:
            # æ¸…ç©ºç‰¹å®šæ ·æœ¬çš„è®°å¿†
            if user_id_base is None:
                user_id_base = "sample"
            user_id = f"{user_id_base}_{sample_idx}"
            self.memory.delete_all(user_id=user_id)
            logger.info(f"å·²æ¸…ç©ºæ ·æœ¬ {sample_idx} (user_id={user_id}) çš„æ‰€æœ‰è®°å¿†")
        else:
            # æ¸…ç©ºæ‰€æœ‰è®°å¿†
            self.memory.reset()
            logger.info("å·²æ¸…ç©ºæ‰€æœ‰è®°å¿†")


def load_longmemeval_s(
    dataset_path: str = "benchmark_longmemeval/dataset/LongMemEval/longmemeval_s_cleaned.json",
    memory: Optional[Memory] = None,
    sample_indices: Optional[List[int]] = None,
    user_id_base: Optional[str] = None,
    infer: bool = True,
    clean_before_add: bool = True
) -> Tuple[LongMemEvalLoader, List[Dict[str, Any]]]:
    """
    åŠ è½½ LongMemEval-S æ•°æ®é›†çš„ä¾¿æ·å‡½æ•°ï¼ˆæ”¯æŒæ ·æœ¬éš”ç¦»ï¼‰
    
    ã€æ ¸å¿ƒéš”ç¦»æœºåˆ¶ã€‘ï¼š
    - æ¯ä¸ªæ ·æœ¬ä½¿ç”¨å”¯ä¸€çš„ user_id: f"{user_id_base}_{idx}"
    - ç¡®ä¿500ä¸ªæ ·æœ¬ä¹‹é—´çš„è®°å¿†å®Œå…¨éš”ç¦»
    
    Args:
        dataset_path: æ•°æ®é›†è·¯å¾„
        memory: mem0 Memory å®ä¾‹
        sample_indices: è¦å¤„ç†çš„æ ·æœ¬ç´¢å¼•åˆ—è¡¨ï¼ŒNone è¡¨ç¤ºå¤„ç†æ‰€æœ‰æ ·æœ¬
        user_id_base: user_id çš„åŸºç¡€åç§°ï¼Œé»˜è®¤ä½¿ç”¨ "sample"
        infer: æ˜¯å¦å¯ç”¨æ¨ç†
        clean_before_add: æ˜¯å¦åœ¨æ·»åŠ å‰æ¸…ç©ºæ¯ä¸ªæ ·æœ¬çš„è®°å¿†
        
    Returns:
        (loader, results) å…ƒç»„
    """
    loader = LongMemEvalLoader(memory=memory)
    
    # åŠ è½½æ•°æ®é›†
    samples = loader.load_dataset(dataset_path, sample_indices=sample_indices)
    logger.info(f"åŠ è½½äº† {len(samples)} ä¸ªæ ·æœ¬")
    
    # å¤„ç†æ¯ä¸ªæ ·æœ¬
    results = []
    for idx, sample in enumerate(samples):
        # ğŸ”¥ å…³é”®ï¼šä½¿ç”¨æ ·æœ¬åœ¨åŸå§‹æ•°æ®é›†ä¸­çš„ç´¢å¼•ï¼ˆå¦‚æœæœ‰ sample_index å­—æ®µï¼‰
        # æˆ–è€…ä½¿ç”¨å½“å‰å¾ªç¯çš„ç´¢å¼•
        original_idx = sample.get('sample_index', idx)
        
        logger.info(f"å¤„ç†æ ·æœ¬ {idx + 1}/{len(samples)} (original_idx={original_idx})")
        
        result = loader.process_sample(
            sample=sample,
            sample_idx=original_idx,  # ğŸ”¥ ä½¿ç”¨åŸå§‹ç´¢å¼•ç¡®ä¿å”¯ä¸€æ€§
            user_id_base=user_id_base,
            infer=infer,
            clean_before_add=clean_before_add
        )
        results.append(result)
    
    return loader, results


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    # ç¤ºä¾‹ 1: åŠ è½½å•ä¸ªæ ·æœ¬ï¼ˆä»æå–çš„æ ·æœ¬æ–‡ä»¶ï¼‰
    loader = LongMemEvalLoader()
    
    # åŠ è½½æå–çš„æ ·æœ¬
    sample_path = "benchmark_longmemeval/dataset/LongMemEval/extracted_samples_index_1.json"
    samples = loader.load_dataset(sample_path)
    
    # åªå¤„ç†ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼ˆlongmemeval_sï¼‰
    s_sample = samples[0]  # longmemeval_s_cleaned çš„æ ·æœ¬
    sample_idx = s_sample.get('sample_index', 1)  # è·å–åŸå§‹ç´¢å¼•
    
    print(f"\n{'='*60}")
    print(f"å¤„ç†æ ·æœ¬ç´¢å¼•: {sample_idx}")
    print(f"é—®é¢˜ID: {s_sample['question_id']}")
    print(f"é—®é¢˜ç±»å‹: {s_sample['question_type']}")
    print(f"é—®é¢˜: {s_sample['question']}")
    print(f"æ ‡å‡†ç­”æ¡ˆ: {s_sample['answer']}")
    print(f"å¯¹è¯ session æ•°: {len(s_sample['haystack_sessions'])}")
    print(f"{'='*60}\n")
    
    # ğŸ”¥ ä½¿ç”¨æ–°çš„ APIï¼šä¼ å…¥ sample_idx
    result = loader.process_sample(
        sample=s_sample,
        sample_idx=sample_idx,  # ä¼ å…¥æ ·æœ¬ç´¢å¼•
        user_id_base="longmemeval_s",  # å¯é€‰ï¼šè‡ªå®šä¹‰åŸºç¡€åç§°
        infer=True,
        query_top_k=5
    )
    
    # æ‰“å°ç»“æœ
    print(f"\næ·»åŠ ç»“æœ:")
    print(f"  - æ ·æœ¬ç´¢å¼•: {result['sample_idx']}")
    print(f"  - User ID: {result['user_id']}")
    print(f"  - æ€»ä¼šè¯æ•°: {result['add_result']['total_sessions']}")
    print(f"  - æˆåŠŸæ·»åŠ : {result['add_result']['added_sessions']}")
    print(f"  - å¤±è´¥: {result['add_result']['failed_sessions']}")
    
    print(f"\næ£€ç´¢åˆ°çš„è®°å¿† ({result['num_memories']} æ¡):")
    for i, memory in enumerate(result['retrieved_memories'][:3], 1):
        print(f"  {i}. {memory}")
    
    # ğŸ”¥ æ¸…ç†ç‰¹å®šæ ·æœ¬çš„è®°å¿†
    loader.reset_memory(sample_idx=sample_idx, user_id_base="longmemeval_s")
    
    print("\n" + "="*60)
    print("ç¤ºä¾‹å®Œæˆï¼")
    print("="*60)
    
    # ç¤ºä¾‹ 2: æ‰¹é‡å¤„ç†å¤šä¸ªæ ·æœ¬ï¼ˆå±•ç¤ºéš”ç¦»æ•ˆæœï¼‰
    print("\n\n" + "="*60)
    print("ç¤ºä¾‹ 2: æ‰¹é‡å¤„ç†ï¼ˆå±•ç¤ºæ ·æœ¬éš”ç¦»ï¼‰")
    print("="*60)
    
    # åŠ è½½å‰ 3 ä¸ªæ ·æœ¬
    loader2, results = load_longmemeval_s(
        dataset_path=sample_path,
        sample_indices=[0, 1],  # åªå¤„ç†å‰ 2 ä¸ªæ ·æœ¬
        user_id_base="demo",
        infer=True
    )
    
    print(f"\næ‰¹é‡å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {len(results)} ä¸ªæ ·æœ¬:")
    for r in results:
        print(f"  - æ ·æœ¬ {r['sample_idx']}: user_id={r['user_id']}, "
              f"æ·»åŠ äº† {r['add_result']['added_sessions']} ä¸ªä¼šè¯, "
              f"æ£€ç´¢åˆ° {r['num_memories']} æ¡è®°å¿†")