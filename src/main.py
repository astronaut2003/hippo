"""
Hippo Agent - FastAPI åº”ç”¨å…¥å£
"""
from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from contextlib import asynccontextmanager
import logging

from src.core.config import settings
from src.core.logger import setup_logging
from src.services.memory_service import get_memory_service
from src.services.llm_service import LLMService
from src.services.chat_service import ChatService
from src.api.v1 import chat, memory

# è®¾ç½®æ—¥å¿—
setup_logging(settings.LOG_LEVEL)
logger = logging.getLogger(__name__)

# å…¨å±€æœåŠ¡å®ä¾‹
memory_service = None
llm_service = None
chat_service = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
    å¯åŠ¨æ—¶åˆå§‹åŒ–æœåŠ¡ï¼Œå…³é—­æ—¶æ¸…ç†èµ„æº
    """
    global memory_service, llm_service, chat_service
    
    logger.info("ğŸš€ æ­£åœ¨å¯åŠ¨ Hippo Agent...")
    
    try:
        # åˆå§‹åŒ– mem0 é…ç½®
        mem0_config = {
            "vector_store": {
                "provider": settings.MEM0_VECTOR_STORE,
                "config": {
                    "dbname": settings.POSTGRES_DB,
                    "host": settings.POSTGRES_HOST,
                    "port": settings.POSTGRES_PORT,
                    "user": settings.POSTGRES_USER,
                    "password": settings.POSTGRES_PASSWORD,
                    "collection_name": settings.MEM0_COLLECTION_NAME,
                    "embedding_model_dims": 1536
                }
            },
            "llm": {
                "provider": "openai",
                "config": {
                    "model": settings.LLM_MODEL,
                    "api_key": settings.OPENAI_API_KEY,
                    "temperature": 0.7
                }
            },
            "embedder": {
                "provider": "openai",
                "config": {
                    "model": settings.EMBEDDING_MODEL,
                    "api_key": settings.OPENAI_API_KEY
                }
            }
        }
        
        # åˆå§‹åŒ–æœåŠ¡
        memory_service = get_memory_service(mem0_config)
        llm_service = LLMService(
            api_key=settings.OPENAI_API_KEY,
            model=settings.LLM_MODEL
        )
        chat_service = ChatService(memory_service, llm_service)
        
        logger.info("âœ… æ‰€æœ‰æœåŠ¡åˆå§‹åŒ–æˆåŠŸ")
        logger.info(f"ğŸ“š æ•°æ®åº“: {settings.POSTGRES_HOST}:{settings.POSTGRES_PORT}/{settings.POSTGRES_DB}")
        logger.info(f"ğŸ¤– LLM æ¨¡å‹: {settings.LLM_MODEL}")
        
    except Exception as e:
        logger.error(f"âŒ æœåŠ¡åˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    yield  # åº”ç”¨è¿è¡Œ
    
    # æ¸…ç†èµ„æº
    logger.info("ğŸ‘‹ æ­£åœ¨å…³é—­ Hippo Agent...")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title=settings.APP_NAME,
    version=settings.APP_VERSION,
    description="å…·å¤‡é•¿æœŸè®°å¿†èƒ½åŠ›çš„æ™ºèƒ½é—®ç­” Agent",
    lifespan=lifespan
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=settings.CORS_ORIGINS_LIST,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# æ³¨å†Œè·¯ç”±
app.include_router(chat.router, prefix="/api/v1")
app.include_router(memory.router, prefix="/api/v1")


@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "Welcome to Hippo Agent API",
        "version": settings.APP_VERSION,
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health")
async def health():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "app": settings.APP_NAME,
        "version": settings.APP_VERSION
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "src.main:app",
        host="0.0.0.0",
        port=8000,
        reload=settings.DEBUG
    )
